{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4147bc06",
   "metadata": {},
   "source": [
    "Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "301c4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, lit, current_timestamp\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import to_date\n",
    "import shutil\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0eba79",
   "metadata": {},
   "source": [
    "Spark initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0eb21729",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AdvancedETL\") \\\n",
    "    .config(\"spark.jars\", \"/app/jars/mssql-jdbc-12.10.1.jre11.jar\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded948c6",
   "metadata": {},
   "source": [
    "Logs handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9af2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"/home/jovyan/etl_pipeline_error_log.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf09ba",
   "metadata": {},
   "source": [
    "Load source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f62a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+----------+------+----------+--------+--------+\n",
      "|OrderID|ProductID|SaleAmount| OrderDate|Region|CustomerID|Discount|Currency|\n",
      "+-------+---------+----------+----------+------+----------+--------+--------+\n",
      "|   1001|      P50|    299.99|01/05/2023|  East|      C100|     0.1|     USD|\n",
      "|   1002|      P72|      NULL|01/05/2023|  West|      C101|    NULL|     EUR|\n",
      "|   1003|      P50|     -10.0|01-06-2023|  East|      C100|    0.05|     GBP|\n",
      "|   1001|      P50|    299.99|01/05/2023|  East|      C100|     0.1|     USD|\n",
      "|   1004|      P99|     150.0|      NULL| South|      C102|     0.2|     USD|\n",
      "+-------+---------+----------+----------+------+----------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+-------------------+---------------+\n",
      "|ProductID|        ProductName|       Category|\n",
      "+---------+-------------------+---------------+\n",
      "|      P50|     Wireless Mouse|    Electronics|\n",
      "|      P72|    Laptop Backpack|    Accessories|\n",
      "|      P99|            USB Hub|    Electronics|\n",
      "|      P12|Notebook Stationery|Office Supplies|\n",
      "|      P88|      Monitor Stand|Office Supplies|\n",
      "+---------+-------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sales_df = spark.read.option(\"header\", True).csv(\"data/sales_data_2.csv\")\n",
    "sales_df.show(5)\n",
    "\n",
    "product_df = spark.read.option(\"header\", True).csv(\"data/product_reference_2.csv\")\n",
    "product_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3de6a9",
   "metadata": {},
   "source": [
    "Null handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "551881d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+----------+------+----------+--------+--------+\n",
      "|OrderID|ProductID|SaleAmount| OrderDate|Region|CustomerID|Discount|Currency|\n",
      "+-------+---------+----------+----------+------+----------+--------+--------+\n",
      "|   1002|      P72|      NULL|01/05/2023|  West|      C101|    NULL|     EUR|\n",
      "+-------+---------+----------+----------+------+----------+--------+--------+\n",
      "\n",
      "+-------+---------+----------+---------+------+----------+--------+--------+\n",
      "|OrderID|ProductID|SaleAmount|OrderDate|Region|CustomerID|Discount|Currency|\n",
      "+-------+---------+----------+---------+------+----------+--------+--------+\n",
      "|   1004|      P99|     150.0|     NULL| South|      C102|     0.2|     USD|\n",
      "+-------+---------+----------+---------+------+----------+--------+--------+\n",
      "\n",
      "+-------+---------+----------+----------+------+----------+--------+--------+\n",
      "|OrderID|ProductID|SaleAmount| OrderDate|Region|CustomerID|Discount|Currency|\n",
      "+-------+---------+----------+----------+------+----------+--------+--------+\n",
      "|   1001|      P50|    299.99|01/05/2023|  East|      C100|     0.1|     USD|\n",
      "|   1003|      P50|     -10.0|01-06-2023|  East|      C100|    0.05|     GBP|\n",
      "|   1001|      P50|    299.99|01/05/2023|  East|      C100|     0.1|     USD|\n",
      "|   1005|      PX1|      89.5|01/07/2023| North|      NULL|     0.0|     USD|\n",
      "|   1006|      P72|     200.0|2023-13-01|  West|      C101|    0.15|     EUR|\n",
      "+-------+---------+----------+----------+------+----------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.filter(col(\"SaleAmount\").isNull()).show()  # Check rows where SaleAmount is null\n",
    "\n",
    "sales_df.filter(col(\"OrderDate\").isNull()).show()   # Check rows where OrderDate is null\n",
    "\n",
    "sales_df.filter((col(\"SaleAmount\").isNotNull()) & (col(\"OrderDate\").isNotNull())).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb31e85",
   "metadata": {},
   "source": [
    "Duplicate removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aeb090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+----------+------+----------+--------+--------+---------------+\n",
      "|OrderID|ProductID|SaleAmount| OrderDate|Region|CustomerID|Discount|Currency|OrderDateParsed|\n",
      "+-------+---------+----------+----------+------+----------+--------+--------+---------------+\n",
      "|   1001|      P50|    299.99|01/05/2023|  East|      C100|     0.1|     USD|     2023-01-05|\n",
      "|   1005|      PX1|      89.5|01/07/2023| North|      NULL|     0.0|     USD|     2023-01-07|\n",
      "|   1007|      P12|     120.0|01/05/2023|  East|      C105|     0.1|     GBP|     2023-01-05|\n",
      "|   1008|      P88|     300.0|02/05/2023| North|      C106|     0.0|     USD|     2023-02-05|\n",
      "|   1009|      P77|       0.0|03/05/2023| South|      C107|    NULL|     USD|     2023-03-05|\n",
      "+-------+---------+----------+----------+------+----------+--------+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df_clean = (\n",
    "    sales_df\n",
    "    .dropna(subset=[\"SaleAmount\", \"OrderDate\"])\n",
    "    .dropDuplicates([\"OrderID\"])\n",
    "    .withColumn(\"OrderDateParsed\", to_date(\"OrderDate\", \"MM/dd/yyyy\")) \n",
    "    .filter(\n",
    "        (col(\"SaleAmount\").cast(\"double\").isNotNull()) &\n",
    "        (col(\"OrderDateParsed\").isNotNull())\n",
    "    )\n",
    ")\n",
    "\n",
    "sales_df_clean.show(5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58813a",
   "metadata": {},
   "source": [
    "Lookup: Join with product reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbb5e9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] enriched_df row count: 15\n",
      "+---------+-------+----------+----------+------+----------+--------+--------+---------------+-------------------+---------------+\n",
      "|ProductID|OrderID|SaleAmount| OrderDate|Region|CustomerID|Discount|Currency|OrderDateParsed|        ProductName|       Category|\n",
      "+---------+-------+----------+----------+------+----------+--------+--------+---------------+-------------------+---------------+\n",
      "|      P50|   1001|    299.99|01/05/2023|  East|      C100|     0.1|     USD|     2023-01-05|     Wireless Mouse|    Electronics|\n",
      "|      PX1|   1005|      89.5|01/07/2023| North|      NULL|     0.0|     USD|     2023-01-07|               NULL|           NULL|\n",
      "|      P12|   1007|     120.0|01/05/2023|  East|      C105|     0.1|     GBP|     2023-01-05|Notebook Stationery|Office Supplies|\n",
      "|      P88|   1008|     300.0|02/05/2023| North|      C106|     0.0|     USD|     2023-02-05|      Monitor Stand|Office Supplies|\n",
      "|      P77|   1009|       0.0|03/05/2023| South|      C107|    NULL|     USD|     2023-03-05|   Portable Speaker|    Electronics|\n",
      "+---------+-------+----------+----------+------+----------+--------+--------+---------------+-------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enriched_df = sales_df_clean.join(product_df, on=\"ProductID\", how=\"left\")\n",
    "print(f\"[INFO] enriched_df row count: {enriched_df.count()}\")\n",
    "enriched_df.show(5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592a060",
   "metadata": {},
   "source": [
    "Currency conversion via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a3840c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] converted_df row count: 15\n",
      "+---------+-------+----------+----------+------+----------+--------+--------+---------------+-------------------+---------------+-----------------+\n",
      "|ProductID|OrderID|SaleAmount| OrderDate|Region|CustomerID|Discount|Currency|OrderDateParsed|        ProductName|       Category|    SaleAmountUSD|\n",
      "+---------+-------+----------+----------+------+----------+--------+--------+---------------+-------------------+---------------+-----------------+\n",
      "|      P50|   1001|    299.99|01/05/2023|  East|      C100|     0.1|     USD|     2023-01-05|     Wireless Mouse|    Electronics|           299.99|\n",
      "|      PX1|   1005|      89.5|01/07/2023| North|      NULL|     0.0|     USD|     2023-01-07|               NULL|           NULL|             89.5|\n",
      "|      P12|   1007|     120.0|01/05/2023|  East|      C105|     0.1|     GBP|     2023-01-05|Notebook Stationery|Office Supplies|159.5744680851064|\n",
      "|      P88|   1008|     300.0|02/05/2023| North|      C106|     0.0|     USD|     2023-02-05|      Monitor Stand|Office Supplies|            300.0|\n",
      "|      P77|   1009|       0.0|03/05/2023| South|      C107|    NULL|     USD|     2023-03-05|   Portable Speaker|    Electronics|              0.0|\n",
      "+---------+-------+----------+----------+------+----------+--------+--------+---------------+-------------------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_exchange_rates():\n",
    "    try:\n",
    "        url = \"https://api.exchangerate-api.com/v4/latest/USD\"\n",
    "        response = requests.get(url)\n",
    "        return response.json().get(\"rates\", {})\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exchange rate API failed: {e}\")\n",
    "        return {\"EUR\": 1.0, \"GBP\": 1.0}\n",
    "\n",
    "exchange_rates = get_exchange_rates()\n",
    "broadcast_rates = spark.sparkContext.broadcast(exchange_rates)\n",
    "\n",
    "\n",
    "@udf(DoubleType())\n",
    "def convert_to_usd(amount, currency):\n",
    "    try:\n",
    "        rate = broadcast_rates.value.get(currency, 1.0)\n",
    "        return float(amount) / float(rate)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Conversion error: amount={amount}, currency={currency}, error={e}\")\n",
    "        return None\n",
    "\n",
    "converted_df = enriched_df.withColumn(\"SaleAmountUSD\", convert_to_usd(col(\"SaleAmount\"), col(\"Currency\")))\n",
    "print(f\"[INFO] converted_df row count: {converted_df.count()}\")\n",
    "converted_df.show(5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7c1f34",
   "metadata": {},
   "source": [
    "Logging conversion info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "785352f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted old log directory at /app/logs/conversion_log\n"
     ]
    }
   ],
   "source": [
    "conversion_log_df = converted_df.withColumn(\"ConversionTime\", current_timestamp()) \\\n",
    "    .select(\"OrderID\", \"Currency\", \"SaleAmount\", \"SaleAmountUSD\", \"ConversionTime\")\n",
    "\n",
    "log_path = \"/app/logs/conversion_log\"\n",
    "\n",
    "# Clean entire log directory if it exists\n",
    "if os.path.exists(log_path):\n",
    "    try:\n",
    "        shutil.rmtree(log_path)  # deletes folder and contents\n",
    "        print(f\"Deleted old log directory at {log_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to delete log directory: {e}\")\n",
    "\n",
    "# Spark will create this folder fresh\n",
    "conversion_log_df.coalesce(1).write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(log_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2f0f7",
   "metadata": {},
   "source": [
    "Error handling with trashold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c761c3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----------+---------+------+----------+--------+--------+---------------+-----------+--------+-------------+-----------+----------+\n",
      "|ProductID|OrderID|SaleAmount|OrderDate|Region|CustomerID|Discount|Currency|OrderDateParsed|ProductName|Category|SaleAmountUSD|ErrorReason|RejectedAt|\n",
      "+---------+-------+----------+---------+------+----------+--------+--------+---------------+-----------+--------+-------------+-----------+----------+\n",
      "+---------+-------+----------+---------+------+----------+--------+--------+---------------+-----------+--------+-------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_df = converted_df.filter(col(\"SaleAmountUSD\").isNull())\n",
    "error_df = error_df.withColumn(\"ErrorReason\", lit(\"Invalid currency or amount\")) \\\n",
    "                   .withColumn(\"RejectedAt\", current_timestamp())\n",
    "error_df.write.mode(\"overwrite\").option(\"header\", True).csv(\"rejected/rejected_records.csv\")\n",
    "error_df.show(5)\n",
    "\n",
    "\n",
    "error_rate = error_df.count() / converted_df.count()\n",
    "if error_rate > 0.05:\n",
    "    raise Exception(f\"[ERROR] Rejected records exceed 5% threshold ({error_rate*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ec0e1",
   "metadata": {},
   "source": [
    "Final clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19f10782",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = converted_df.filter(col(\"SaleAmountUSD\").isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586eb113",
   "metadata": {},
   "source": [
    "Write to SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "806cf1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = \"jdbc:sqlserver://host.docker.internal:1433;databaseName=SalesDB;encrypt=true;trustServerCertificate=true\"\n",
    "\n",
    "db_props = {\n",
    "    \"user\": \"sa\",\n",
    "    \"password\": \"qwe123!@#\",\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n",
    "\n",
    "final_df.write.jdbc(url=jdbc_url, table=\"SalesEnriched\", mode=\"append\", properties=db_props)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241108b",
   "metadata": {},
   "source": [
    "Wrire rejected records to SQL for tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f248e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.write.jdbc(url=jdbc_url, table=\"RejectedRecords\", mode=\"append\", properties=db_props)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
