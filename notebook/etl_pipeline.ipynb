{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4147bc06",
   "metadata": {},
   "source": [
    "Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301c4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, lit, current_timestamp\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import to_date\n",
    "import shutil\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0eba79",
   "metadata": {},
   "source": [
    "Spark initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb21729",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AdvancedETL\") \\\n",
    "    .config(\"spark.jars\", \"/app/jars/mssql-jdbc-12.10.1.jre11.jar\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded948c6",
   "metadata": {},
   "source": [
    "Logs handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"/home/jovyan/etl_pipeline_error_log.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf09ba",
   "metadata": {},
   "source": [
    "Load source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sales_df = spark.read.option(\"header\", True).csv(\"data/sales_data_2.csv\")\n",
    "sales_df.show(5)\n",
    "\n",
    "product_df = spark.read.option(\"header\", True).csv(\"data/product_reference_2.csv\")\n",
    "product_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3de6a9",
   "metadata": {},
   "source": [
    "Null handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551881d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.filter(col(\"SaleAmount\").isNull()).show()  # Check rows where SaleAmount is null\n",
    "\n",
    "sales_df.filter(col(\"OrderDate\").isNull()).show()   # Check rows where OrderDate is null\n",
    "\n",
    "sales_df.filter((col(\"SaleAmount\").isNotNull()) & (col(\"OrderDate\").isNotNull())).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb31e85",
   "metadata": {},
   "source": [
    "Duplicate removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df_clean = (\n",
    "    sales_df\n",
    "    .dropna(subset=[\"SaleAmount\", \"OrderDate\"])\n",
    "    .dropDuplicates([\"OrderID\"])\n",
    "    .withColumn(\"OrderDateParsed\", to_date(\"OrderDate\", \"MM/dd/yyyy\")) \n",
    "    .filter(\n",
    "        (col(\"SaleAmount\").cast(\"double\").isNotNull()) &\n",
    "        (col(\"OrderDateParsed\").isNotNull())\n",
    "    )\n",
    ")\n",
    "\n",
    "sales_df_clean.show(5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58813a",
   "metadata": {},
   "source": [
    "Lookup: Join with product reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_df = sales_df_clean.join(product_df, on=\"ProductID\", how=\"left\")\n",
    "print(f\"[INFO] enriched_df row count: {enriched_df.count()}\")\n",
    "enriched_df.show(5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592a060",
   "metadata": {},
   "source": [
    "Currency conversion via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3840c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exchange_rates():\n",
    "    try:\n",
    "        url = \"https://api.exchangerate-api.com/v4/latest/USD\"\n",
    "        response = requests.get(url)\n",
    "        return response.json().get(\"rates\", {})\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exchange rate API failed: {e}\")\n",
    "        return {\"EUR\": 1.0, \"GBP\": 1.0}\n",
    "\n",
    "exchange_rates = get_exchange_rates()\n",
    "broadcast_rates = spark.sparkContext.broadcast(exchange_rates)\n",
    "\n",
    "\n",
    "@udf(DoubleType())\n",
    "def convert_to_usd(amount, currency):\n",
    "    try:\n",
    "        rate = broadcast_rates.value.get(currency, 1.0)\n",
    "        return float(amount) / float(rate)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Conversion error: amount={amount}, currency={currency}, error={e}\")\n",
    "        return None\n",
    "\n",
    "converted_df = enriched_df.withColumn(\"SaleAmountUSD\", convert_to_usd(col(\"SaleAmount\"), col(\"Currency\")))\n",
    "print(f\"[INFO] converted_df row count: {converted_df.count()}\")\n",
    "converted_df.show(5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7c1f34",
   "metadata": {},
   "source": [
    "Logging conversion info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785352f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_log_df = converted_df.withColumn(\"ConversionTime\", current_timestamp()) \\\n",
    "    .select(\"OrderID\", \"Currency\", \"SaleAmount\", \"SaleAmountUSD\", \"ConversionTime\")\n",
    "\n",
    "log_path = \"/app/logs/conversion_log\"\n",
    "\n",
    "# Clean entire log directory if it exists\n",
    "if os.path.exists(log_path):\n",
    "    try:\n",
    "        shutil.rmtree(log_path)  # deletes folder and contents\n",
    "        print(f\"Deleted old log directory at {log_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to delete log directory: {e}\")\n",
    "\n",
    "# Spark will create this folder fresh\n",
    "conversion_log_df.coalesce(1).write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(log_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2f0f7",
   "metadata": {},
   "source": [
    "Error handling with trashold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = converted_df.filter(col(\"SaleAmountUSD\").isNull())\n",
    "error_df = error_df.withColumn(\"ErrorReason\", lit(\"Invalid currency or amount\")) \\\n",
    "                   .withColumn(\"RejectedAt\", current_timestamp())\n",
    "error_df.write.mode(\"overwrite\").option(\"header\", True).csv(\"rejected/rejected_records.csv\")\n",
    "error_df.show(5)\n",
    "\n",
    "\n",
    "error_rate = error_df.count() / converted_df.count()\n",
    "if error_rate > 0.05:\n",
    "    raise Exception(f\"[ERROR] Rejected records exceed 5% threshold ({error_rate*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ec0e1",
   "metadata": {},
   "source": [
    "Final clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f10782",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = converted_df.filter(col(\"SaleAmountUSD\").isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586eb113",
   "metadata": {},
   "source": [
    "Write to SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806cf1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = \"jdbc:sqlserver://host.docker.internal:1433;databaseName=SalesDB;encrypt=true;trustServerCertificate=true\"\n",
    "\n",
    "db_props = {\n",
    "    \"user\": \"sa\",\n",
    "    \"password\": \"qwe123!@#$\",\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n",
    "\n",
    "final_df.write.jdbc(url=jdbc_url, table=\"SalesEnriched\", mode=\"append\", properties=db_props)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241108b",
   "metadata": {},
   "source": [
    "Wrire rejected records to SQL for tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.write.jdbc(url=jdbc_url, table=\"RejectedRecords\", mode=\"append\", properties=db_props)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
