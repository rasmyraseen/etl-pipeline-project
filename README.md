
# ğŸš€ Advanced ETL Pipeline - PySpark + Docker

This project implements an advanced ETL pipeline using PySpark. It includes:

- Data ingestion from CSV
- External API currency conversion
- Data validation, enrichment, and transformation
- Loading into Microsoft SQL Server
- Logging and error handling

---

## ğŸ“ Project Structure

```
etl_pipeline_project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sales_data.csv
â”‚   â””â”€â”€ product_reference.csv
â”‚
â”œâ”€â”€ jars/
â”‚   â””â”€â”€ mssql-jdbc-12.10.1.jre11.jar
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ conversion_log.csv
â”‚
â”œâ”€â”€ rejected/
â”‚   â””â”€â”€ rejected_records.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ AdvancedETL.ipynb      # Jupyter notebook version
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ advanced_etl.py        # PySpark script version (if any)
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile (optional)
â”œâ”€â”€ create_tables.sql
â””â”€â”€ README.md
```

---

## ğŸ§° Setup Instructions

### âœ… Prerequisites

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)
- Optional: Microsoft SQL Server running locally or remotely (port `1433`)

### âœ… Clone the Project

```bash
git clone https://github.com/yourusername/etl_pipeline_project.git
cd etl_pipeline_project
```

### âœ… Start the Jupyter + PySpark Environment

```bash
docker-compose up
```

Once started, find the Jupyter Notebook URL (with token) in the logs:

```bash
docker logs etl-pipeline
```

ğŸ”— Example: `http://localhost:8888/?token=abc123...`

---

## â–¶ï¸ How to Run the ETL

1. Open the Jupyter Notebook in browser using the token URL.
2. Navigate to:  
   `notebooks/AdvancedETL.ipynb`
3. Run all cells from top to bottom.

âœ… It will:
- Load source data
- Fetch exchange rates from API
- Convert currencies
- Validate and enrich data
- Log conversions and errors
- Load data to SQL Server (`SalesEnriched` table)

---

## ğŸ—„ï¸ SQL Server Setup

Before running the ETL, run the schema creation script:

```bash
# Inside your SQL Server client
USE SalesDB;
GO

-- Execute this
CREATE TABLE SalesEnriched (
    ...
);
```

The script is provided in:  
`create_tables.sql`

---

## ğŸ’¡ Tips

- To stop/start the environment:
  ```bash
  docker-compose stop
  docker-compose start
  ```
- To rebuild from scratch:
  ```bash
  docker-compose down
  docker-compose up --build
  ```
- To view logs:
  ```bash
  docker logs etl-pipeline
  ```
